{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Model Training & Evaluation\n",
    "## Real Estate Price Prediction\n",
    "\n",
    "**Author:** Nicolas  \n",
    "**Date:** 2025-01-09  \n",
    "**Objective:** EntraÃ®ner, comparer et optimiser plusieurs modÃ¨les ML pour la prÃ©diction de prix immobiliers\n",
    "\n",
    "---\n",
    "\n",
    "### Table of Contents\n",
    "1. [Data Loading](#1-data-loading)\n",
    "2. [Baseline Model](#2-baseline-model)\n",
    "3. [Linear Models](#3-linear-models)\n",
    "4. [Tree-Based Models](#4-tree-based-models)\n",
    "5. [Ensemble Methods](#5-ensemble-methods)\n",
    "6. [Model Comparison](#6-model-comparison)\n",
    "7. [Hyperparameter Tuning](#7-hyperparameter-tuning)\n",
    "8. [Final Model Evaluation](#8-final-model-evaluation)\n",
    "9. [Feature Importance](#9-feature-importance)\n",
    "10. [Model Interpretation (SHAP)](#10-model-interpretation)\n",
    "11. [Model Persistence](#11-model-persistence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import joblib\n",
    "import json\n",
    "from time import time\n",
    "import warnings\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "# Advanced ML\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Model interpretation\n",
    "import shap\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Seed pour reproductibilitÃ©\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donnÃ©es prÃ©parÃ©es\n",
    "print(\"=\" * 80)\n",
    "print(\"CHARGEMENT DES DONNÃ‰ES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with open('../data/processed_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "y_train_log = data['y_train_log']\n",
    "y_test_log = data['y_test_log']\n",
    "feature_names = data['feature_names']\n",
    "\n",
    "print(f\"\\nâœ… DonnÃ©es chargÃ©es:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_test:  {X_test.shape}\")\n",
    "print(f\"  Features: {len(feature_names)}\")\n",
    "print(f\"\\n  Target statistics (train):\")\n",
    "print(f\"    Mean:   {y_train.mean():,.2f} â‚¬\")\n",
    "print(f\"    Median: {y_train.median():,.2f} â‚¬\")\n",
    "print(f\"    Std:    {y_train.std():,.2f} â‚¬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour Ã©valuer les modÃ¨les\n",
    "def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Calcule et affiche les mÃ©triques de rÃ©gression.\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name} - MÃ©triques:\")\n",
    "    print(f\"  RMSE:  {rmse:,.2f} â‚¬\")\n",
    "    print(f\"  MAE:   {mae:,.2f} â‚¬\")\n",
    "    print(f\"  MAPE:  {mape:.2f}%\")\n",
    "    print(f\"  RÂ²:    {r2:.4f}\")\n",
    "    \n",
    "    return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2}\n",
    "\n",
    "# Dictionnaire pour stocker les rÃ©sultats\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"BASELINE MODEL - PrÃ©diction par la moyenne\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Baseline: prÃ©dire toujours la moyenne du train set\n",
    "y_pred_baseline = np.full(len(y_test), y_train.mean())\n",
    "results['Baseline (Mean)'] = evaluate_model(y_test, y_pred_baseline, \"Baseline (Mean)\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Le baseline nous donne un point de rÃ©fÃ©rence.\")\n",
    "print(\"   Tout modÃ¨le doit faire significativement mieux que cela!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODÃˆLES LINÃ‰AIRES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 3.1 Linear Regression\n",
    "print(\"\\n[1/4] Linear Regression...\")\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "results['Linear Regression'] = evaluate_model(y_test, y_pred_lr, \"Linear Regression\")\n",
    "\n",
    "# 3.2 Ridge Regression (L2 regularization)\n",
    "print(\"\\n[2/4] Ridge Regression...\")\n",
    "ridge = Ridge(alpha=10.0, random_state=RANDOM_STATE)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "results['Ridge'] = evaluate_model(y_test, y_pred_ridge, \"Ridge\")\n",
    "\n",
    "# 3.3 Lasso Regression (L1 regularization)\n",
    "print(\"\\n[3/4] Lasso Regression...\")\n",
    "lasso = Lasso(alpha=10.0, random_state=RANDOM_STATE, max_iter=10000)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "results['Lasso'] = evaluate_model(y_test, y_pred_lasso, \"Lasso\")\n",
    "\n",
    "# 3.4 ElasticNet (L1 + L2)\n",
    "print(\"\\n[4/4] ElasticNet...\")\n",
    "elastic = ElasticNet(alpha=10.0, l1_ratio=0.5, random_state=RANDOM_STATE, max_iter=10000)\n",
    "elastic.fit(X_train, y_train)\n",
    "y_pred_elastic = elastic.predict(X_test)\n",
    "results['ElasticNet'] = evaluate_model(y_test, y_pred_elastic, \"ElasticNet\")\n",
    "\n",
    "print(\"\\nâœ… ModÃ¨les linÃ©aires entraÃ®nÃ©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tree-Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODÃˆLES Ã€ BASE D'ARBRES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 4.1 Decision Tree\n",
    "print(\"\\n[1/2] Decision Tree...\")\n",
    "dt = DecisionTreeRegressor(max_depth=10, min_samples_split=20, random_state=RANDOM_STATE)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "results['Decision Tree'] = evaluate_model(y_test, y_pred_dt, \"Decision Tree\")\n",
    "\n",
    "# 4.2 Random Forest\n",
    "print(\"\\n[2/2] Random Forest...\")\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=15, min_samples_split=10, \n",
    "                           random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "results['Random Forest'] = evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
    "\n",
    "print(\"\\nâœ… ModÃ¨les Ã  base d'arbres entraÃ®nÃ©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensemble Methods (Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MÃ‰THODES D'ENSEMBLE (BOOSTING)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 5.1 Gradient Boosting\n",
    "print(\"\\n[1/4] Gradient Boosting...\")\n",
    "start = time()\n",
    "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5,\n",
    "                               random_state=RANDOM_STATE)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "results['Gradient Boosting'] = evaluate_model(y_test, y_pred_gb, \"Gradient Boosting\")\n",
    "print(f\"  Training time: {time() - start:.2f}s\")\n",
    "\n",
    "# 5.2 XGBoost\n",
    "print(\"\\n[2/4] XGBoost...\")\n",
    "start = time()\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5,\n",
    "                             random_state=RANDOM_STATE, n_jobs=-1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "results['XGBoost'] = evaluate_model(y_test, y_pred_xgb, \"XGBoost\")\n",
    "print(f\"  Training time: {time() - start:.2f}s\")\n",
    "\n",
    "# 5.3 LightGBM\n",
    "print(\"\\n[3/4] LightGBM...\")\n",
    "start = time()\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=5,\n",
    "                              random_state=RANDOM_STATE, n_jobs=-1, verbose=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "results['LightGBM'] = evaluate_model(y_test, y_pred_lgb, \"LightGBM\")\n",
    "print(f\"  Training time: {time() - start:.2f}s\")\n",
    "\n",
    "# 5.4 CatBoost\n",
    "print(\"\\n[4/4] CatBoost...\")\n",
    "start = time()\n",
    "cat_model = CatBoostRegressor(iterations=100, learning_rate=0.1, depth=5,\n",
    "                              random_state=RANDOM_STATE, verbose=0)\n",
    "cat_model.fit(X_train, y_train)\n",
    "y_pred_cat = cat_model.predict(X_test)\n",
    "results['CatBoost'] = evaluate_model(y_test, y_pred_cat, \"CatBoost\")\n",
    "print(f\"  Training time: {time() - start:.2f}s\")\n",
    "\n",
    "print(\"\\nâœ… ModÃ¨les de boosting entraÃ®nÃ©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARAISON DES MODÃˆLES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# CrÃ©er un DataFrame de rÃ©sultats\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values('R2', ascending=False)\n",
    "\n",
    "print(\"\\nðŸ“Š Classement des modÃ¨les (par RÂ²):\")\n",
    "print(results_df.to_string())\n",
    "\n",
    "# Sauvegarder les rÃ©sultats\n",
    "results_df.to_csv('../models/model_comparison.csv')\n",
    "print(\"\\nâœ… RÃ©sultats sauvegardÃ©s: ../models/model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des performances\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# RÂ² Score\n",
    "results_df['R2'].plot(kind='barh', ax=axes[0, 0], color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('RÂ² Score (plus Ã©levÃ© = meilleur)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('RÂ²')\n",
    "axes[0, 0].axvline(0.9, color='green', linestyle='--', alpha=0.5, label='Excellent (>0.9)')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# RMSE\n",
    "results_df['RMSE'].sort_values().plot(kind='barh', ax=axes[0, 1], color='coral', edgecolor='black')\n",
    "axes[0, 1].set_title('RMSE (plus bas = meilleur)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('RMSE (â‚¬)')\n",
    "\n",
    "# MAE\n",
    "results_df['MAE'].sort_values().plot(kind='barh', ax=axes[1, 0], color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_title('MAE (plus bas = meilleur)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('MAE (â‚¬)')\n",
    "\n",
    "# MAPE\n",
    "results_df['MAPE'].sort_values().plot(kind='barh', ax=axes[1, 1], color='gold', edgecolor='black')\n",
    "axes[1, 1].set_title('MAPE (plus bas = meilleur)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('MAPE (%)')\n",
    "axes[1, 1].axvline(10, color='green', linestyle='--', alpha=0.5, label='Excellent (<10%)')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Graphique sauvegardÃ©: ../models/model_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier le meilleur modÃ¨le\n",
    "best_model_name = results_df.index[0]\n",
    "best_r2 = results_df.iloc[0]['R2']\n",
    "best_rmse = results_df.iloc[0]['RMSE']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ðŸ† MEILLEUR MODÃˆLE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nModÃ¨le: {best_model_name}\")\n",
    "print(f\"RÂ²:     {best_r2:.4f}\")\n",
    "print(f\"RMSE:   {best_rmse:,.2f} â‚¬\")\n",
    "print(f\"\\nðŸ’¡ Ce modÃ¨le sera optimisÃ© dans la section suivante\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTIMISATION DES HYPERPARAMÃˆTRES (GridSearchCV)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# On va optimiser XGBoost (gÃ©nÃ©ralement le meilleur)\n",
    "print(\"\\nOptimisation de XGBoost...\")\n",
    "\n",
    "# Grille de paramÃ¨tres\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "print(f\"\\nGrille de recherche: {len(param_grid['n_estimators']) * len(param_grid['max_depth']) * len(param_grid['learning_rate']) * len(param_grid['subsample']) * len(param_grid['colsample_bytree'])} combinaisons\")\n",
    "print(\"\\nâš ï¸  Cela peut prendre plusieurs minutes...\")\n",
    "\n",
    "# GridSearchCV avec validation croisÃ©e\n",
    "start = time()\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb.XGBRegressor(random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    param_grid=param_grid,\n",
    "    scoring='r2',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "training_time = time() - start\n",
    "\n",
    "print(f\"\\nâœ… Optimisation terminÃ©e en {training_time:.2f}s ({training_time/60:.1f} minutes)\")\n",
    "print(f\"\\nMeilleurs paramÃ¨tres:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# ModÃ¨le optimisÃ©\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred_best = best_xgb.predict(X_test)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARAISON AVANT/APRÃˆS OPTIMISATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nXGBoost (dÃ©faut):\")\n",
    "for metric, value in results['XGBoost'].items():\n",
    "    print(f\"  {metric}: {value:,.4f}\" if metric == 'R2' else f\"  {metric}: {value:,.2f}\")\n",
    "\n",
    "results['XGBoost (Optimized)'] = evaluate_model(y_test, y_pred_best, \"\\nXGBoost (Optimized)\")\n",
    "\n",
    "# Improvement\n",
    "r2_improvement = (results['XGBoost (Optimized)']['R2'] - results['XGBoost']['R2']) / results['XGBoost']['R2'] * 100\n",
    "rmse_improvement = (results['XGBoost']['RMSE'] - results['XGBoost (Optimized)']['RMSE']) / results['XGBoost']['RMSE'] * 100\n",
    "\n",
    "print(f\"\\nðŸ“ˆ AmÃ©lioration:\")\n",
    "print(f\"  RÂ² : +{r2_improvement:.2f}%\")\n",
    "print(f\"  RMSE: -{rmse_improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Ã‰VALUATION FINALE DU MEILLEUR MODÃˆLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# PrÃ©dictions vs rÃ©alitÃ©\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# 1. Scatter plot: PrÃ©dictions vs RÃ©alitÃ©\n",
    "axes[0].scatter(y_test, y_pred_best, alpha=0.5, s=30)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "             'r--', lw=2, label='PrÃ©diction parfaite')\n",
    "axes[0].set_xlabel('Prix RÃ©el (â‚¬)', fontsize=11)\n",
    "axes[0].set_ylabel('Prix PrÃ©dit (â‚¬)', fontsize=11)\n",
    "axes[0].set_title('PrÃ©dictions vs RÃ©alitÃ©', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Distribution des erreurs\n",
    "errors = y_test - y_pred_best\n",
    "axes[1].hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(0, color='red', linestyle='--', linewidth=2, label='Erreur nulle')\n",
    "axes[1].set_xlabel('Erreur de prÃ©diction (â‚¬)', fontsize=11)\n",
    "axes[1].set_ylabel('FrÃ©quence', fontsize=11)\n",
    "axes[1].set_title(f'Distribution des Erreurs (Moyenne: {errors.mean():,.0f}â‚¬)', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "\n",
    "# 3. Erreurs relatives (%)\n",
    "relative_errors = np.abs((y_test - y_pred_best) / y_test) * 100\n",
    "axes[2].hist(relative_errors, bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "axes[2].axvline(10, color='green', linestyle='--', linewidth=2, label='Erreur 10%')\n",
    "axes[2].set_xlabel('Erreur relative (%)', fontsize=11)\n",
    "axes[2].set_ylabel('FrÃ©quence', fontsize=11)\n",
    "axes[2].set_title(f'Distribution des Erreurs Relatives (MÃ©diane: {np.median(relative_errors):.1f}%)', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/final_model_evaluation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Statistiques sur les erreurs\n",
    "print(\"\\nStatistiques sur les erreurs:\")\n",
    "print(f\"  Erreur moyenne:         {errors.mean():,.2f} â‚¬\")\n",
    "print(f\"  Erreur mÃ©diane:         {errors.median():,.2f} â‚¬\")\n",
    "print(f\"  Ã‰cart-type des erreurs: {errors.std():,.2f} â‚¬\")\n",
    "print(f\"\\n  Erreur relative moyenne:  {relative_errors.mean():.2f}%\")\n",
    "print(f\"  Erreur relative mÃ©diane:  {np.median(relative_errors):.2f}%\")\n",
    "print(f\"  % de prÃ©dictions Ã  Â±10%:  {(relative_errors <= 10).sum() / len(relative_errors) * 100:.1f}%\")\n",
    "print(f\"  % de prÃ©dictions Ã  Â±20%:  {(relative_errors <= 20).sum() / len(relative_errors) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"IMPORTANCE DES FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Extraire l'importance des features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': best_xgb.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 features les plus importantes:\")\n",
    "print(feature_importance.head(20).to_string(index=False))\n",
    "\n",
    "# Visualisation\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "feature_importance.head(20).plot(kind='barh', x='feature', y='importance', \n",
    "                                 ax=ax, legend=False, edgecolor='black', alpha=0.7)\n",
    "ax.set_title('Top 20 Features - Importance', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Importance', fontsize=11)\n",
    "ax.set_ylabel('Feature', fontsize=11)\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Sauvegarder\n",
    "feature_importance.to_csv('../models/feature_importance.csv', index=False)\n",
    "print(\"\\nâœ… Importance sauvegardÃ©e: ../models/feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Interpretation (SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INTERPRÃ‰TATION DU MODÃˆLE AVEC SHAP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nâš ï¸  Calcul des SHAP values (peut prendre 1-2 minutes)...\")\n",
    "\n",
    "# CrÃ©er l'explainer SHAP\n",
    "explainer = shap.TreeExplainer(best_xgb)\n",
    "\n",
    "# Calculer SHAP values (sur un Ã©chantillon pour la rapiditÃ©)\n",
    "sample_size = min(500, len(X_test))\n",
    "X_test_sample = X_test.sample(n=sample_size, random_state=RANDOM_STATE)\n",
    "shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "print(\"âœ… SHAP values calculÃ©es\")\n",
    "\n",
    "# 1. Summary plot (importance globale)\n",
    "print(\"\\nGÃ©nÃ©ration du SHAP Summary Plot...\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test_sample, show=False, max_display=20)\n",
    "plt.title('SHAP Summary Plot - Impact des Features', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/shap_summary_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ InterprÃ©tation:\")\n",
    "print(\"  - Chaque point reprÃ©sente une prÃ©diction\")\n",
    "print(\"  - Couleur rouge = valeur Ã©levÃ©e de la feature\")\n",
    "print(\"  - Couleur bleue = valeur faible de la feature\")\n",
    "print(\"  - Position droite = impact positif sur le prix\")\n",
    "print(\"  - Position gauche = impact nÃ©gatif sur le prix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Force plot pour une prÃ©diction individuelle\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SHAP FORCE PLOT - Explication d'une prÃ©diction\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Choisir un exemple\n",
    "idx = 0\n",
    "example = X_test_sample.iloc[idx]\n",
    "example_shap = shap_values[idx]\n",
    "\n",
    "print(f\"\\nExemple #{idx}:\")\n",
    "print(f\"  Valeur rÃ©elle: {y_test.iloc[idx]:,.2f} â‚¬\")\n",
    "print(f\"  PrÃ©diction:    {best_xgb.predict(example.to_frame().T)[0]:,.2f} â‚¬\")\n",
    "\n",
    "# Force plot\n",
    "shap.force_plot(explainer.expected_value, example_shap, example, \n",
    "                matplotlib=True, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/shap_force_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… SHAP plots sauvegardÃ©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAUVEGARDE DU MODÃˆLE FINAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Sauvegarder le modÃ¨le\n",
    "joblib.dump(best_xgb, '../models/best_model.pkl')\n",
    "print(\"\\nâœ… ModÃ¨le sauvegardÃ©: ../models/best_model.pkl\")\n",
    "\n",
    "# Sauvegarder les mÃ©tadonnÃ©es\n",
    "metadata = {\n",
    "    'model_name': 'XGBoost (Optimized)',\n",
    "    'model_type': 'XGBRegressor',\n",
    "    'best_params': grid_search.best_params_,\n",
    "    'metrics': results['XGBoost (Optimized)'],\n",
    "    'feature_names': feature_names,\n",
    "    'n_features': len(feature_names),\n",
    "    'training_samples': len(X_train),\n",
    "    'test_samples': len(X_test),\n",
    "    'date': '2025-01-09'\n",
    "}\n",
    "\n",
    "with open('../models/model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"âœ… MÃ©tadonnÃ©es sauvegardÃ©es: ../models/model_metadata.json\")\n",
    "\n",
    "# Test de chargement\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST DE CHARGEMENT DU MODÃˆLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "loaded_model = joblib.load('../models/best_model.pkl')\n",
    "test_prediction = loaded_model.predict(X_test.head(1))\n",
    "\n",
    "print(f\"\\nâœ… ModÃ¨le chargÃ© avec succÃ¨s\")\n",
    "print(f\"   Test prediction: {test_prediction[0]:,.2f} â‚¬\")\n",
    "print(f\"   Actual value:    {y_test.iloc[0]:,.2f} â‚¬\")\n",
    "print(f\"   Difference:      {abs(test_prediction[0] - y_test.iloc[0]):,.2f} â‚¬ ({abs(test_prediction[0] - y_test.iloc[0])/y_test.iloc[0]*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### ModÃ¨les entraÃ®nÃ©s:\n",
    "1. **Baseline** (Mean prediction)\n",
    "2. **Linear Models**: LinearRegression, Ridge, Lasso, ElasticNet\n",
    "3. **Tree-Based**: DecisionTree, RandomForest\n",
    "4. **Boosting**: GradientBoosting, XGBoost, LightGBM, CatBoost\n",
    "\n",
    "### Meilleur modÃ¨le:\n",
    "- **XGBoost (Optimized)** aprÃ¨s GridSearchCV\n",
    "- HyperparamÃ¨tres optimisÃ©s par validation croisÃ©e (5-fold CV)\n",
    "- Performance mesurÃ©e sur ensemble de test indÃ©pendant\n",
    "\n",
    "### InterprÃ©tabilitÃ©:\n",
    "- **Feature Importance**: Identification des variables les plus importantes\n",
    "- **SHAP Values**: Explication dÃ©taillÃ©e de l'impact de chaque feature\n",
    "- **Force Plots**: Explication de prÃ©dictions individuelles\n",
    "\n",
    "### Production-ready:\n",
    "- ModÃ¨le sauvegardÃ© avec joblib (`.pkl`)\n",
    "- MÃ©tadonnÃ©es complÃ¨tes (JSON)\n",
    "- Scaler sauvegardÃ© pour preprocessing\n",
    "- Reproductible (RANDOM_STATE=42)\n",
    "\n",
    "### Prochaines Ã©tapes potentielles:\n",
    "1. DÃ©ploiement avec FastAPI ou Flask\n",
    "2. Monitoring en production\n",
    "3. RÃ©-entraÃ®nement pÃ©riodique\n",
    "4. A/B testing de nouvelles features\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
